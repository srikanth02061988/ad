import json
from openai import AzureOpenAI

client = AzureOpenAI(
    api_version="2024-02-01",
    azure_endpoint="https://effopenai.openai.azure.com/",
    api_key="7896c56d537d4f19803a4ac85bd9bc9"
)

def call_llm_model(prompt):
    response = client.chat.completions.create(
        model="ajitTest",
        messages=[
            {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

def detect_closed_domain_hallucination(reference_text, input_text, completion, ground_truth, num_runs=5, threshold=0.5):
    hallucination_count = 0
    prompt_template = """
    You are an AI assistant tasked with detecting closed-domain hallucinations in the following response.
    A closed-domain hallucination is an inaccurate or unmotivated claim about the given reference text.
    Please answer with "Yes" or "No" and provide a brief explanation.

    Reference: {reference_text}
    Input: {input_text}
    Response: {completion}
    Ground Truth: {ground_truth}
    Does the response contain closed-domain hallucinations? Explain your reasoning.
    """

    results = []

    def get_hallucination_judgment(reference_text, input_text, completion, ground_truth):
        prompt = prompt_template.format(reference_text=reference_text, input_text=input_text, completion=completion, ground_truth=ground_truth)
        response = call_llm_model(prompt)
        return response

    for _ in range(num_runs):
        judgment = get_hallucination_judgment(reference_text, input_text, completion, ground_truth)
        results.append({
            "reference_text": reference_text,
            "input_text": input_text,
            "completion": completion,
            "ground_truth": ground_truth,
            "judgment": judgment
        })
        if "yes" in judgment.lower():
            hallucination_count += 1

    hallucination_score = hallucination_count / num_runs
    is_hallucination = hallucination_score > threshold
    return is_hallucination, hallucination_score, results

data = [
    {
        "reference": "Penguins are a group of aquatic, flightless birds living almost exclusively in the Southern Hemisphere.",
        "input": "Tell me a fact about penguins.",
        "output": "Penguins can fly in the same way that airplanes do.",
        "ground_truth": "Penguins are flightless birds."
    },
    {
        "reference": "Paris is the capital and most populous city of France.",
        "input": "What is the capital of France?",
        "output": "The capital of France is Paris.",
        "ground_truth": "The capital of France is Paris."
    }
]

num_runs = 5
all_results = []

for row in data:
    reference_text = row.get('reference')
    input_prompt = row.get('input')
    output_prompt = row.get('output')
    ground_truth = row.get('ground_truth')

    if reference_text and input_prompt and output_prompt and ground_truth:
        is_hallucination, score, results = detect_closed_domain_hallucination(reference_text, input_prompt, output_prompt, ground_truth, num_runs)
        all_results.extend(results)
        print(f"Reference: {reference_text}")
        print(f"Input: {input_prompt}")
        print(f"Output: {output_prompt}")
        print(f"Ground Truth: {ground_truth}")
        print(f"Is Hallucination: {is_hallucination}, Score: {score}")
        print("="*80)

# Save results to a JSON file
results_path = "/path/to/save/results.json"  # Update with your desired save path
with open(results_path, 'w') as file:
    json.dump(all_results, file, indent=4)

print(f"Results saved to {results_path}")
