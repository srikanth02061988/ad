from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("RemoveColumnFromDeltaTable") \
    .getOrCreate()

delta_table = spark.read.format("delta").load("dbfs:/user/hive/warehouse/rai_payload_synth_hallucination_results")

print("Schema before dropping column:")
delta_table.printSchema()

columns_to_keep = [col for col in delta_table.columns if col != 'event_timestamp']
delta_table_updated = delta_table.select(*columns_to_keep)

delta_table_updated.write.format("delta").option("mergeSchema", "true").mode("overwrite").save("dbfs:/user/hive/warehouse/rai_payload_synth_hallucination_results")

updated_table = spark.read.format("delta").load("dbfs:/user/hive/warehouse/rai_payload_synth_hallucination_results")
print("Schema after dropping column:")
updated_table.printSchema()

print("Updated Delta table saved without 'event_timestamp' column.")
