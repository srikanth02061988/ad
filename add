import streamlit as st
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
import psycopg2
from psycopg2.extras import execute_values
import numpy as np
import logging
import requests
import json
import uuid
from openai import AzureOpenAI

client = AzureOpenAI(
    api_version="2024-02-01",
    azure_endpoint="https://effopenai.openai.azure.com/",
    api_key="7896c56d537df41980034ac85b9d9bc9"
)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

azure_endpoint = "https://effopenai.openai.azure.com"
azure_api_key = "7896c56d537df41980034ac85b9d9bc9"
embedding_deployment = "TEB-Robin"
completion_deployment = "ajitTest"

headers = {
    "Content-Type": "application/json",
    "api-key": azure_api_key
}

def get_embeddings(text, endpoint, headers, deployment=embedding_deployment):
    try:
        logger.info(f"Generating embeddings for the text chunk: {text[:30]}...")
        url = f"{endpoint.strip()}/openai/deployments/{deployment}/embeddings?api-version=2024-02-15-preview"
        logger.info(f"Request URL: {url}")
        logger.info(f"Request Headers: {headers}")
        data = {"input": text}
        logger.info(f"Request Data: {data}")
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        embedding = result['data'][0]['embedding']
        logger.info("Embeddings generated successfully.")
        print("Generated Embeddings:", embedding)
        return embedding
    except requests.exceptions.RequestException as e:
        logger.error(f"Error generating embeddings: {e}")
        st.error(f"An error occurred while generating embeddings: {e}")
        return None

def get_pdf_text(pdf_docs):
    text = ""
    try:
        logger.info("Extracting text from PDF...")
        with pdfplumber.open(pdf_docs) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    cleaned_text = page_text.replace('\x00', '')
                    text += cleaned_text
        logger.info("Text extraction from PDF successful.")
    except Exception as e:
        logger.error(f"Error extracting text from PDF: {e}")
        st.error(f"An error occurred while extracting text from PDF: {e}")
    return text

def get_text_chunks(text):
    logger.info("Splitting text into chunks...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)
    chunks = text_splitter.split_text(text)
    logger.info(f"Text split into {len(chunks)} chunks.")
    return chunks

def store_embeddings_in_db(pdf_id, text_chunks, endpoint, headers):
    try:
        logger.info("Connecting to PostgreSQL database...")
        conn = psycopg2.connect(
            host="npceffepsql.postgres.database.azure.com",
            port="5432",
            database="Digital_marketing_Embeddings",
            user="pgadmin",
            password="npceeff8kS"
        )

        with conn.cursor() as cur:
            logger.info("Creating table if it does not exist...")
            cur.execute("""
            CREATE TABLE IF NOT EXISTS embeddings (
                id BIGSERIAL PRIMARY KEY,
                pdf_id UUID,
                content TEXT,
                embedding VECTOR(1536)
            )
            """)
            conn.commit()

        embeddings = []
        for chunk in text_chunks:
            logger.info(f"Generating embedding for chunk: {chunk[:30]}...")
            embedding = get_embeddings(chunk, endpoint, headers)
            if embedding is not None:
                embedding_vector = list(map(float, embedding))
                embeddings.append((pdf_id, chunk, embedding_vector))
            else:
                logger.error("Failed to generate embedding for a chunk, skipping it.")
        
        if embeddings:
            with conn.cursor() as cur:
                logger.info("Inserting embeddings into the database...")
                execute_values(cur, "INSERT INTO embeddings (pdf_id, content, embedding) VALUES %s", embeddings)
                conn.commit()
        else:
            logger.error("No embeddings generated to store in the database.")
        conn.close()
    except Exception as e:
        logger.error(f"Error storing embeddings in database: {e}")
        st.error(f"An error occurred while storing embeddings in the database: {e}")

def retrieve_embeddings_from_db(pdf_id):
    try:
        logger.info("Connecting to PostgreSQL database for retrieval...")
        conn = psycopg2.connect(
            host="npceffepsql.postgres.database.azure.com",
            port="5432",
            database="Digital_marketing_Embeddings",
            user="pgadmin",
            password="npceeff8kS"
        )

        with conn.cursor() as cur:
            logger.info(f"Retrieving embeddings for PDF ID: {pdf_id}...")
            cur.execute("SELECT content, embedding::text FROM embeddings WHERE pdf_id = %s", (pdf_id,))
            rows = cur.fetchall()
        conn.close()

        if rows:
            docs = [row[0] for row in rows]
            embeddings = np.array([list(map(float, row[1][1:-1].split(','))) for row in rows], dtype=np.float32)
            print("Retrieved Embeddings:", embeddings)
            return docs, embeddings
        else:
            logger.info("No embeddings found for the given PDF ID.")
            return None, None
    except Exception as e:
        logger.error(f"Error retrieving embeddings from database: {e}")
        st.error(f"An error occurred while retrieving embeddings from the database: {e}")
        return None, None

def find_relevant_chunks(question, docs, embeddings, top_k=5):
    return docs[:top_k]

def generate_responses(question, relevant_docs, client, deployment="ajitTest"):
    try:
        logger.info("Generating responses for the question...")
        combined_docs = "\n\n".join(relevant_docs)
        prompt = f"Based on the following documents, answer the question: {question}\n\nDocuments:\n\n{combined_docs}"

        response = client.chat.completions.create(
            model=deployment,
            messages=[
                {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
                {"role": "user", "content": prompt}
            ]
        )

        result = response.model_dump_json(indent=2)
        text_response = response.choices[0].message.content.strip()
        logger.info(f"Response from OpenAI: {text_response}")

        return text_response
    except Exception as e:
        logger.error(f"Error generating responses: {e}")
        st.error(f"An error occurred while generating responses: {e}")
        return None

def main():
    st.set_page_config(page_title="Digital Marketing")
    st.header("Generate Derivative Content")
    st.sidebar.title("Menu")

    tab1, tab2 = st.tabs(["Upload & Generate", "Ask Questions"])

    with tab1:
        pdf_docs = st.sidebar.file_uploader("Upload your PDF Files", type=["pdf"])

        if pdf_docs is not None and st.sidebar.button("Submit PDF"):
            with st.spinner("Processing..."):
                raw_text = get_pdf_text(pdf_docs)
                if raw_text:
                    text_chunks = get_text_chunks(raw_text)
                    pdf_id = str(uuid.uuid4())
                    store_embeddings_in_db(pdf_id, text_chunks, azure_endpoint, headers)
                    st.session_state["pdf_id"] = pdf_id
                    st.session_state["text_chunks"] = text_chunks
                    st.session_state["category"] = None
                    st.sidebar.success("PDF processed and embeddings stored.")

        if "pdf_id" in st.session_state:
            category = st.selectbox("Select the category to search within:", ["Twitter", "LinkedIn", "Other"])
            if st.button("Submit"):
                with open("prompts.json", "r") as file:
                    prompts = json.load(file)
                system_prompt = prompts.get(category, "Default prompt")
                text_chunks = st.session_state.get("text_chunks", [])
                text_response = generate_responses(system_prompt, text_chunks, client)
                if text_response:
                    st.write("Response:")
                    st.write(text_response)
                    st.download_button("Download Response", data=text_response, file_name="response.txt")
                else:
                    st.error("Failed to generate responses.")
            if st.button("Next"):
                st.session_state["category"] = category
                st.experimental_rerun()

    with tab2:
        if "pdf_id" in st.session_state:
            category = st.session_state.get("category", "Other")
            user_question = st.text_area("Ask a Question based on the uploaded PDF", height=200)
            if st.button("Submit Question"):
                with st.spinner("Retrieving and processing..."):
                    pdf_id = st.session_state["pdf_id"]
                    docs, embeddings = retrieve_embeddings_from_db(pdf_id)
                    if docs and embeddings is not None and embeddings.any():
                        relevant_docs = find_relevant_chunks(user_question, docs, embeddings)
                        text_response = generate_responses(user_question, relevant_docs, client)
                        if text_response:
                            st.write("Response:")
                            st.write(text_response)
                            st.download_button("Download Response", data=text_response, file_name="response.txt")
                        else:
                            st.error("Failed to generate responses.")
                    else:
                        st.error("No relevant embeddings found for the uploaded PDF.")
        else:
            st.warning("Please upload and process a PDF in the 'Upload & Generate' tab first.")

if __name__ == "__main__":
    main()
