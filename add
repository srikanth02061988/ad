import os
import json
from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip
from openai import AzureOpenAI

# Configuring Spark with Delta Lake
builder = SparkSession.builder.appName("HallucinationDetection") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
spark = configure_spark_with_delta_pip(builder).getOrCreate()

# Azure OpenAI configuration
client = AzureOpenAI(
    api_version="2024-02-01",
    azure_endpoint="https://effopenai.openai.azure.com/",
    api_key="7896c56d537d4f19803a4ac85bd9bc9"
)

# Function to call the Azure LLM model
def call_llm_model(prompt):
    response = client.chat.completions.create(
        model="ajitTest",  # Replace with your model deployment name
        messages=[
            {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

# Load data from Delta Table
delta_table_path = "dbfs:/user/hive/warehouse/rai_processed"
df = spark.read.format("delta").load(delta_table_path)
df.show(2, False)

# Function to extract the prompt
def extract_prompt(value):
    try:
        if isinstance(value, str):
            parsed_value = json.loads(value)
            return parsed_value.get("prompt", None)
    except json.JSONDecodeError:
        return None

# Function to detect hallucinations
def detect_open_domain_hallucination(input_text, completion, num_runs=5, threshold=0.5):
    hallucination_count = 0
    prompt_template = """
    You are an AI assistant tasked with detecting open-domain hallucinations in the following response.
    An open-domain hallucination is an inaccurate or unmotivated claim about the world.
    Please answer with "Yes" or "No" and provide a brief explanation.

    Input: {input_text}
    Response: {completion}
    Does the response contain open-domain hallucinations? Explain your reasoning.
    """

    def get_hallucination_judgment(input_text, completion):
        prompt = prompt_template.format(input_text=input_text, completion=completion)
        response = call_llm_model(prompt)
        return response

    for _ in range(num_runs):
        judgment = get_hallucination_judgment(input_text, completion)
        if "yes" in judgment.lower():
            hallucination_count += 1

    hallucination_score = hallucination_count / num_runs
    return hallucination_score > threshold, hallucination_score

# Process rows in the dataframe
results = []
for row in df.collect():
    input_value = row.input.value if hasattr(row, 'input') else None
    output_value = row.output.value if hasattr(row, 'output') and row.output is not None else None

    if input_value and output_value:
        input_prompt = extract_prompt(input_value)
        output_prompt = extract_prompt(output_value)
        if input_prompt and output_prompt:
            is_hallucination, score = detect_open_domain_hallucination(input_prompt, output_prompt)
            results.append((input_prompt, output_prompt, is_hallucination, score))
            print(f"Input: {input_prompt}")
            print(f"Output: {output_prompt}")
            print(f"Is Hallucination: {is_hallucination}, Score: {score}")
            print("="*80)

# Save results to a new Delta table
results_df = spark.createDataFrame(results, schema=["input_prompt", "output_response", "is_hallucination", "score"])
results_df.write.format("delta").mode("overwrite").save("/path/to/save/results")
results_df.show(10, False)

