import streamlit as st
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
import psycopg2
from psycopg2.extras import execute_values
import numpy as np
import logging
import requests
import json
import uuid
from azure.identity import AzureOpenAI
from fpdf import FPDF
from PIL import Image
from io import BytesIO

# Initialize the Azure OpenAI client
client = AzureOpenAI(
    api_version="2024-02-01",
    azure_endpoint="https://effopenai.openai.azure.com/",
    api_key="7896c56d537df41980034ac85b9d9bc9"
)

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Azure and database configuration
azure_endpoint = "https://effopenai.openai.azure.com"
azure_api_key = "7896c56d537df41980034ac85b9d9bc9"
embedding_deployment = "TEB-Robin"
completion_deployment = "ajitTest"

headers = {
    "Content-Type": "application/json",
    "api-key": azure_api_key
}

header_url = "https://your_header_image_url.com/header.png"
footer_path = "/path/to/your/local/footer.png"

db_config = {
    "host": "neopeffpga1.postgres.database.azure.com",
    "port": "5432",
    "database": "Digital_marketing_Embeddings",
    "user": "pgadmin",
    "password": "neopeffK8$"
}

def get_embeddings(text, endpoint, headers, deployment):
    try:
        logger.info("Generating embeddings for the text chunk...")
        url = f"{endpoint}/openai/deployments/{deployment}/embeddings?api-version=2024-02-15-preview"
        data = {"input": text}
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        embedding = response.json()['data'][0]['embedding']
        logger.info("Embeddings generated successfully.")
        return embedding
    except requests.exceptions.RequestException as e:
        logger.error(f"Error generating embeddings: {e}")
        return None

def get_pdf_text(pdf_docs):
    text = ""
    try:
        logger.info("Extracting text from PDF...")
        with pdfplumber.open(pdf_docs) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    cleaned_text = page_text.replace('\n', ' ')
                    text += cleaned_text
        logger.info("Text extraction from PDF successful.")
        return text
    except Exception as e:
        logger.error(f"Error extracting text from PDF: {e}")
        return None

def get_text_chunks(text):
    logger.info("Splitting text into chunks...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)
    chunks = text_splitter.split_text(text)
    logger.info(f"Text split into {len(chunks)} chunks.")
    return chunks

def store_embeddings_in_db(pdf_id, text_chunks, endpoint, headers):
    try:
        logger.info("Connecting to PostgreSQL database...")
        conn = psycopg2.connect(**db_config)
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS embeddings (
                    id SERIAL PRIMARY KEY,
                    pdf_id UUID,
                    content TEXT,
                    embedding VECTOR(1536)
                )
            """)
            conn.commit()

            embeddings = []
            for chunk in text_chunks:
                logger.info("Generating embedding for chunk...")
                embedding = get_embeddings(chunk, endpoint, headers, embedding_deployment)
                if embedding is not None:
                    embeddings.append((pdf_id, chunk, embedding))
                else:
                    logger.error("Failed to generate embedding for a chunk, skipping it.")

            if embeddings:
                execute_values(cur, """
                    INSERT INTO embeddings (pdf_id, content, embedding) VALUES %s
                """, embeddings)
                conn.commit()
                logger.info("Embeddings inserted into the database.")
            else:
                logger.error("No embeddings generated to store in the database.")
    except Exception as e:
        logger.error(f"Error storing embeddings in database: {e}")
    finally:
        if conn:
            conn.close()

def retrieve_embeddings_from_db(pdf_id):
    try:
        logger.info("Connecting to PostgreSQL database for retrieval...")
        conn = psycopg2.connect(**db_config)
        with conn.cursor() as cur:
            cur.execute("SELECT content, embedding::TEXT FROM embeddings WHERE pdf_id = %s", (pdf_id,))
            rows = cur.fetchall()
            if rows:
                docs = [row[0] for row in rows]
                embeddings = np.array([list(map(float, row[1][1:-1].split(','))) for row in rows], dtype=np.float32)
                logger.info("Retrieved embeddings successfully.")
                return docs, embeddings
            else:
                logger.info("No embeddings found for the given PDF ID.")
                return None, None
    except Exception as e:
        logger.error(f"Error retrieving embeddings from database: {e}")
        return None, None
    finally:
        if conn:
            conn.close()

def find_relevant_chunks(question, docs, embeddings, top_k=5):
    # Implement a function to find relevant chunks based on the question and embeddings
    pass

def generate_responses(question, relevant_docs, client, deployment):
    try:
        logger.info("Generating responses for the question...")
        combined_docs = "\n\n".join(relevant_docs)
        responses = []
        for _ in range(2):
            response = client.chat_completions.create(
                model=deployment,
                messages=[
                    {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
                    {"role": "user", "content": question},
                    {"role": "user", "content": combined_docs}
                ]
            )
            text_response = response.choices[0].message.content.strip()
            responses.append(text_response)
            logger.info("Response from OpenAI: %s", text_response)
        return responses
    except Exception as e:
        logger.error(f"Error generating responses: {e}")
        return None, None

def save_response_as_pdf(response, file_name, header_url, footer_path):
    pdf = FPDF()
    pdf.add_page()
    
    # Add header image from URL
    response = requests.get(header_url)
    header_img = Image.open(BytesIO(response.content))
    header_img.save('header_temp.png')
    pdf.image('header_temp.png', 10, 8, 190)  # Adjust dimensions as needed

    pdf.set_font("Arial", size=12)
    pdf.ln(20)  # Adjust this to move the text below the header
    for line in response.split('\n'):
        pdf.cell(200, 10, txt=line, ln=True)

    # Add footer image from local file
    pdf.image(footer_path, 10, 270, 190)  # Adjust dimensions as needed

    pdf.output(file_name)

def main():
    st.set_page_config(page_title="Derived Content UC Generator App")
    st.sidebar.title("Menu")
    
    tab1, tab2 = st.tabs(["Upload & Generate", "Developer Prompt"])
    
    with tab1:
        pdf_docs = st.sidebar.file_uploader("Upload your PDF files", type=["pdf"])
        if pdf_docs and st.sidebar.button("Submit PDF"):
            with st.spinner("Processing..."):
                raw_text = get_pdf_text(pdf_docs)
                if raw_text:
                    pdf_id = str(uuid.uuid4())
                    text_chunks = get_text_chunks(raw_text)
                    store_embeddings_in_db(pdf_id, text_chunks, azure_endpoint, headers)
                    st.session_state["pdf_id"] = pdf_id
                    st.success("PDF processed and embeddings stored.")
                else:
                    st.error("Failed to process the PDF.")
    
    with tab2:
        if "pdf_id" in st.session_state:
            pdf_id = st.session_state["pdf_id"]
            user_question = st.text_input("Ask a question based on the uploaded PDF", height=200)
            if st.button("Submit Question"):
                docs, embeddings = retrieve_embeddings_from_db(pdf_id)
                if docs and embeddings:
                    relevant_docs = find_relevant_chunks(user_question, docs, embeddings)
                    if relevant_docs:
                        responses = generate_responses(user_question, relevant_docs, client, completion_deployment)
                        if responses:
                            st.write("Response 1:")
                            col1, col2 = st.columns([1, 1])
                            with col1:
                                response1 = responses[0]
                                st.write(response1)
                                if st.button("üëç Response 1"):
                                    st.session_state["selected_response"] = response1
                            with col2:
                                response2 = responses[1]
                                st.write(response2)
                                if st.button("üëç Response 2"):
                                    st.session_state["selected_response"] = response2
                            
                            selected_response = st.session_state.get("selected_response", responses[0])
                            if st.button("Download Response as PDF"):
                                save_response_as_pdf(selected_response, "response.pdf", header_url, footer_path)
                                st.success("Response downloaded as PDF.")
                        else:
                            st.error("Failed to generate responses.")
                    else:
                        st.error("No relevant embeddings found for the uploaded PDF.")
        else:
            st.warning("Please upload and process a PDF in the 'Upload & Generate' tab first.")

if __name__ == "__main__":
    main()
