mport os
from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip
from transformers import pipeline, set_seed

# Configure Spark with Delta Lake
builder = SparkSession.builder.appName("HallucinationDetection") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")

spark = configure_spark_with_delta_pip(builder).getOrCreate()

# Initialize the question-answering pipeline
set_seed(42)
qa_pipeline = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')

# Load data from Delta Table
delta_table_path = "path_to_your_delta_table"
df = spark.read.format("delta").load(delta_table_path)

def detect_open_domain_hallucination(input_text, completion, num_runs=5, threshold=0.5):
    hallucination_count = 0
    prompt_template = """
    You are an AI assistant tasked with detecting open-domain hallucinations in the following response. 
    An open-domain hallucination is an inaccurate or unmotivated claim about the world.
    Please answer with "Yes" or "No" and provide a brief explanation.

    Input: {input_text}

    Response: {completion}

    Does the response contain open-domain hallucinations? Explain your reasoning.
    """

    def get_hallucination_judgment(input_text, completion):
        prompt = prompt_template.format(input_text=input_text, completion=completion)
        response = qa_pipeline(question=prompt, context=completion)
        return response['answer'].strip()

    for _ in range(num_runs):
        judgment = get_hallucination_judgment(input_text, completion)
        if "yes" in judgment.lower():
            hallucination_count += 1

    hallucination_score = hallucination_count / num_runs
    return hallucination_score > threshold, hallucination_score

# Iterate over rows in the DataFrame and calculate hallucinations
results = []

for row in df.collect():
    input_text = row['input_prompt']
    completion = row['output_response']
    is_hallucination, score = detect_open_domain_hallucination(input_text, completion)
    results.append((input_text, completion, is_hallucination, score))

# Print or store the results
for result in results:
    print(f"Input: {result[0]}")
    print(f"Output: {result[1]}")
    print(f"Is Hallucination: {result[2]}, Score: {result[3]}")
    print("-" * 80)

# Optionally, save results back to Delta Table
results_df = spark.createDataFrame(results, schema=["input_prompt", "output_response", "is_hallucination", "score"])
results_df.write.format("delta").mode("overwrite").save("path_to_save_results_delta_table")
