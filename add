# Rename the 'timestamp' column in the DataFrame to avoid conflict during the initial write
results_df = results_df.withColumnRenamed("timestamp", "event_timestamp")

# Write the results to the Delta table with schema merging enabled
results_df.select(
    "event_timestamp", 
    "ssc_RAI_session_id", 
    "ssc_RAI_chainid", 
    "ssc_RAI_appcode", 
    "hallucination_score", 
    "is_hallucination"
).write.format("delta").option("mergeSchema", "true").mode("overwrite").save("dbfs:/user/hive/warehouse/rai_payload_synth_hallucination_results")

print("Saved results to Delta table with 'event_timestamp'.")

# Read the Delta table again to ensure changes are applied
delta_table = spark.read.format("delta").load("dbfs:/user/hive/warehouse/rai_payload_synth_hallucination_results")

# Rename 'event_timestamp' back to 'timestamp' and drop the original 'timestamp' column if exists
final_df = delta_table.withColumnRenamed("event_timestamp", "timestamp").drop("event_timestamp")

# Save the final results back to the Delta table
final_df.write.format("delta").option("mergeSchema", "true").mode("overwrite").save("dbfs:/user/hive/warehouse/rai_payload_synth_hallucination_results")

print("Final results saved to Delta table with 'timestamp'.")
