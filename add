import streamlit as st
from htbuilder import HtmlElement, div, hr, p, styles, a, img
from htbuilder.units import percent, px
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.lib.units import inch
from io import BytesIO
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
import psycopg2
from psycopg2.extras import execute_values
import numpy as np
import requests
import json
import uuid
from openai import AzureOpenAI

# Initialize logging
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Azure OpenAI client initialization
try:
    client = AzureOpenAI(
        api_version="2024-02-01",
        azure_endpoint="https://effopenai.openai.azure.com/",
        api_key="7896c56d537df41980034ac85b9d9bc9"
    )
    logger.info("Azure OpenAI client initialized successfully.")
except Exception as e:
    logger.error(f"Failed to initialize Azure OpenAI client: {e}")

# Azure and database configuration
azure_endpoint = "https://effopenai.openai.azure.com"
azure_api_key = "7896c56d537df41980034ac85b9d9bc9"
embedding_deployment = "TEB-Robin"
completion_deployment = "ajitTest"

headers = {
    "Content-Type": "application/json",
    "api-key": azure_api_key
}

def get_embeddings(text, endpoint, headers, deployment=embedding_deployment):
    try:
        logger.info("Generating embeddings...")
        url = f"{endpoint.strip()}/openai/deployments/{deployment}/embeddings?api-version=2024-02-15-preview"
        data = {"input": text}
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        embedding = result['data'][0]['embedding']
        logger.info("Embeddings generated successfully.")
        return embedding
    except requests.exceptions.RequestException as e:
        logger.error(f"An error occurred while generating embeddings: {e}")
        st.error(f"An error occurred while generating embeddings: {e}")
        return None

def get_pdf_text(pdf_docs):
    text = ""
    try:
        with pdfplumber.open(pdf_docs) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    cleaned_text = page_text.replace('\x00', '')
                    text += cleaned_text
        logger.info("Text extracted from PDF successfully.")
    except Exception as e:
        logger.error(f"An error occurred while extracting text from PDF: {e}")
        st.error(f"An error occurred while extracting text from PDF: {e}")
    return text

def get_text_chunks(text):
    logger.info("Splitting text into chunks...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)
    chunks = text_splitter.split_text(text)
    logger.info(f"Text split into {len(chunks)} chunks.")
    return chunks

def store_embeddings_in_db(pdf_id, text_chunks, endpoint, headers):
    try:
        logger.info("Connecting to PostgreSQL database...")
        conn = psycopg2.connect(
            host="npceffepsql.postgres.database.azure.com",
            port="5432",
            database="Digital_marketing_Embeddings",
            user="pgadmin",
            password="npceeff8kS"
        )
        with conn.cursor() as cur:
            cur.execute("""
            CREATE TABLE IF NOT EXISTS embeddings (
                id BIGSERIAL PRIMARY KEY,
                pdf_id UUID,
                content TEXT,
                embedding VECTOR(1536)
            )
            """)
            conn.commit()
            logger.info("Table checked/created successfully.")

        embeddings = []
        for chunk in text_chunks:
            embedding = get_embeddings(chunk, endpoint, headers)
            if embedding is not None:
                embedding_vector = np.array(embedding, dtype=np.float32)
                embeddings.append((pdf_id, chunk, embedding_vector.tolist()))
            else:
                logger.warning("Embedding generation returned None.")

        if embeddings:
            with conn.cursor() as cur:
                execute_values(cur, "INSERT INTO embeddings (pdf_id, content, embedding) VALUES %s", embeddings)
                conn.commit()
            logger.info("Embeddings stored in the database successfully.")
        conn.close()
    except Exception as e:
        logger.error(f"An error occurred while storing embeddings in the database: {e}")
        st.error(f"An error occurred while storing embeddings in the database: {e}")

def retrieve_embeddings_from_db(pdf_id):
    try:
        logger.info("Retrieving embeddings from the database...")
        conn = psycopg2.connect(
            host="npceffepsql.postgres.database.azure.com",
            port="5432",
            database="Digital_marketing_Embeddings",
            user="pgadmin",
            password="npceeff8kS"
        )
        with conn.cursor() as cur:
            cur.execute("SELECT content, embedding::text FROM embeddings WHERE pdf_id = %s", (pdf_id,))
            rows = cur.fetchall()
        conn.close()

        if rows:
            docs = [row[0] for row in rows]
            embeddings = np.array([np.fromstring(row[1][1:-1], sep=',') for row in rows], dtype=np.float32)
            logger.info("Embeddings retrieved successfully.")
            return docs, embeddings
        else:
            logger.warning("No embeddings found for the given PDF ID.")
            return None, None
    except Exception as e:
        logger.error(f"An error occurred while retrieving embeddings from the database: {e}")
        st.error(f"An error occurred while retrieving embeddings from the database: {e}")
        return None, None

def find_relevant_chunks(question, docs, embeddings, top_k=5):
    return docs[:top_k]

def generate_responses(question, relevant_docs, client, deployment="ajitTest", num_responses=3):
    try:
        combined_docs = "\n\n".join(relevant_docs)
        prompt = f"Based on the following documents, answer the question: {question}\n\nDocuments:\n\n{combined_docs}"

        responses = []
        for _ in range(num_responses):
            response = client.chat.completions.create(
                model=deployment,
                messages=[
                    {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
                    {"role": "user", "content": prompt}
                ]
            )
            text_response = response.choices[0].message.content.strip()
            responses.append(text_response)
        logger.info("Responses generated successfully.")
        return responses
    except Exception as e:
        logger.error(f"An error occurred while generating responses: {e}")
        st.error(f"An error occurred while generating responses: {e}")
        return []

def create_pdf(text_response, filename):
    buffer = BytesIO()
    p = canvas.Canvas(buffer, pagesize=letter)
    
    # Draw text response
    text_object = p.beginText(40, 700)
    text_object.setFont("Helvetica", 12)
    max_width = 7.5 * inch
    lines = text_response.split('\n')
    for line in lines:
        while len(line) > 0:
            part = line[:int(max_width / 6)]
            text_object.textLine(part)
            line = line[int(max_width / 6):]
    p.drawText(text_object)

    p.showPage()
    p.save()
    buffer.seek(0)
    return buffer, filename

def layout(*args):
    style = """
    <style>
      #MainMenu {visibility: hidden;}
      footer {visibility: hidden;}
      header {visibility: hidden;}
      .stApp { margin-top: 50px; }
    </style>
    """
    st.markdown(style, unsafe_allow_html=True)

    style_header_div = styles(
        position="fixed",
        top=0,
        left=0,
        right=0,
        background_color="rgb(0,32,96)",
        color="white",
        padding_left=px(10),
        padding_top=px(10),
        padding_bottom=px(10),
        z_index=1000,
        text_align="left",
    )

    style_footer_div = styles(
        position="fixed",
        left=0,
        bottom=0,
        width=percent(100),
        background_color="rgb(0,32,96)",
        color="white",
        text_align="center",
        padding=px(10, 10),
        z_index=1000,
    )

    header = div(
        style=style_header_div
    )(
        p()(a(_href="https://united.states", style=styles(color="white", text_decoration="none"))("United States - Asset Manager")),
        div(style=styles(float="right"))(
            a(_href="https://contact.us", style=styles(color="white", margin_right=px(20)))("Contact Us"),
            a(_href="https://company.websites", style=styles(color="white"))("Company Websites")
        )
    )

    footer = div(
        style=style_footer_div
    )(
        hr(style=styles(border_style="solid", border_color="white")),
        p()("2024 State Street Corporation. All rights reserved."),
        p()("By accessing this website, you agree to be bound by the terms and conditions that appear herein."),
        p()("These terms and conditions are subject to change. State Street reserves the right to modify these terms and conditions, which it may do by posting changes to the website."),
        p()("If you do not agree with these terms and conditions, please do not access the website."),
        p()(a(_href="https://privacy.notice", style=styles(color="white"))("Global Privacy Notice"), " | ",
           a(_href="https://cookie.settings", style=styles(color="white"))("Cookie Settings"), " | ",
           a(_href="https://cookie.disclosure", style=styles(color="white"))("Cookie Disclosure"), " | ",
           a(_href="https://legal", style=styles(color="white"))("Legal"), " | ",
           a(_href="https://sitemap", style=styles(color="white"))("Sitemap"))
    )

    st.markdown(str(header), unsafe_allow_html=True)
    st.markdown(str(footer), unsafe_allow_html=True)

    # Ensure footer is shown only after all content
    st.markdown(
        """
        <style>
        .reportview-container .main footer {visibility: hidden;}
        .reportview-container .main footer::before {
            content: ' ';
            display: block;
            height: 200px;
        }
        </style>
        """, unsafe_allow_html=True
    )

    body = div()
    for arg in args:
        if isinstance(arg, str):
            body(arg)
        elif isinstance(arg, HtmlElement):
            body(arg)

    return body

def main():
    st.set_page_config(page_title="Digital Marketing Derived Content Generator")
    
    st.sidebar.title("Menu")
    st.sidebar.file_uploader("Upload your PDF Files", type=["pdf"], key="pdf_upload")

    tab1, tab2 = st.tabs(["Upload & Generate", "Developer Prompt"])

    if "pdf_id" not in st.session_state:
        st.session_state.pdf_id = None

    if "text_chunks" not in st.session_state:
        st.session_state.text_chunks = []

    if "responses" not in st.session_state:
        st.session_state.responses = []

    if "selected_response" not in st.session_state:
        st.session_state.selected_response = None

    if "current_prompt_file" not in st.session_state:
        st.session_state.current_prompt_file = "prompts.json"

    layout("")

    with tab1:
        pdf_docs = st.sidebar.file_uploader("Upload your PDF Files", type=["pdf"], key="pdf_upload_tab1")

        if pdf_docs and st.sidebar.button("Submit PDF", key="submit_pdf_tab1"):
            with st.spinner("Processing..."):
                raw_text = get_pdf_text(pdf_docs)
                if raw_text:
                    text_chunks = get_text_chunks(raw_text)
                    pdf_id = str(uuid.uuid4())
                    store_embeddings_in_db(pdf_id, text_chunks, azure_endpoint, headers)
                    st.session_state.pdf_id = pdf_id
                    st.session_state.text_chunks = text_chunks
                    st.sidebar.success("PDF processed and embeddings stored.")
                else:
                    logger.warning("No text extracted from PDF.")
                    st.error("Failed to extract text from the uploaded PDF.")

        if st.session_state.pdf_id:
            category = st.selectbox("Select the category to search within:", ["Twitter", "LinkedIn", "Other"], key="category_tab1")
            button_label = "Generate" if not st.session_state.responses else "Regenerate"
            if st.button(button_label, key="generate_tab1"):
                with open(st.session_state.current_prompt_file, "r") as file:
                    try:
                        prompts = json.load(file)
                        logger.info("Prompts loaded successfully.")
                    except json.JSONDecodeError:
                        logger.error("Error loading prompts from JSON.")
                        st.error("Error loading prompts. Please check the prompts.json file.")
                        return
                system_prompt = prompts.get(category, "Default prompt")
                text_chunks = st.session_state.get("text_chunks", [])
                responses = generate_responses(system_prompt, text_chunks, client)
                if responses:
                    st.session_state.responses = responses

                    # Cycle through prompt files
                    if st.session_state.current_prompt_file == "prompts.json":
                        st.session_state.current_prompt_file = "prompts1.json"
                    elif st.session_state.current_prompt_file == "prompts1.json":
                        st.session_state.current_prompt_file = "prompts2.json"
                    else:
                        st.session_state.current_prompt_file = "prompts.json"

        if st.session_state.responses:
            st.write("Responses:")
            selected_response = st.radio("Select a response to download:", st.session_state.responses, key="responses_radio_tab1")
            st.session_state.selected_response = selected_response

            if st.session_state.selected_response:
                st.write("Selected Response:")
                st.write(st.session_state.selected_response)
                pdf_buffer, pdf_filename = create_pdf(st.session_state.selected_response, f"{category}.pdf")
                st.download_button(
                    f"Download Selected Response as {category}.pdf",
                    data=pdf_buffer,
                    file_name=pdf_filename,
                    mime="application/pdf",
                    key="download_button_tab1"
                )

    with tab2:
        if st.session_state.pdf_id:
            user_question = st.text_area("Ask a Question based on the uploaded PDF", height=200, key="question_tab2")
            if st.button("Submit", key="submit_tab2"):
                with st.spinner("Retrieving and processing..."):
                    pdf_id = st.session_state.pdf_id
                    docs, embeddings = retrieve_embeddings_from_db(pdf_id)
                    if docs and embeddings is not None and embeddings.any():
                        relevant_docs = find_relevant_chunks(user_question, docs, embeddings)
                        responses = generate_responses(user_question, relevant_docs, client)
                        if responses:
                            st.session_state.responses = responses

        if st.session_state.responses:
            st.write("Responses:")
            selected_response = st.radio("Select a response to download:", st.session_state.responses, key="responses_radio_tab2")
            st.session_state.selected_response = selected_response

            if st.session_state.selected_response:
                st.write("Selected Response:")
                st.write(st.session_state.selected_response)
                pdf_buffer, pdf_filename = create_pdf(st.session_state.selected_response, f"{category}.pdf")
                st.download_button(
                    f"Download Selected Response as {category}.pdf",
                    data=pdf_buffer,
                    file_name=pdf_filename,
                    mime="application/pdf",
                    key="download_button_tab2"
                )

if __name__ == "__main__":
    main()

