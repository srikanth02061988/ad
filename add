import os
import openai

# Azure OpenAI configuration
openai.api_type = "azure"
openai.api_version = "2024-02-01"
openai.api_base = 
openai.api_key = 

# Hardcoded input and output
input_text = "Who were the founders of Microsoft?"
output_text = "Microsoft was founded by Bill Gates and Paul Allen."

# System prompt for hallucination detection
system_prompt = """
You are an AI assistant tasked with detecting open-domain hallucinations in the following response.
An open-domain hallucination is an inaccurate or unmotivated claim about the world.
Please answer with "Yes" or "No" and provide a brief explanation.

Input: {input_text}
Response: {output_text}
Does the response contain open-domain hallucinations? Explain your reasoning.
"""

# Function to call the Azure LLM model
def call_llm_model(prompt):
    response = openai.ChatCompletion.create(
        engine="",  # Replace with your model deployment name
        messages=[
            {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message['content'].strip()

# Function to detect hallucinations
def detect_hallucinations(input_text, output_text, num_runs=5):
    hallucination_count = 0
    prompt = system_prompt.format(input_text=input_text, output_text=output_text)

    for _ in range(num_runs):
        response = call_llm_model(prompt)
        print(f"Response {_ + 1}: {response}")
        if "yes" in response.lower():
            hallucination_count += 1

    hallucination_score = hallucination_count / num_runs
    is_hallucination = hallucination_score > 0.5

    return is_hallucination, hallucination_score

# Run the hallucination detection
is_hallucination, score = detect_hallucinations(input_text, output_text)

# Display the results
print(f"\nFinal Result:")
print(f"Input: {input_text}")
print(f"Output: {output_text}")
print(f"Is Hallucination: {is_hallucination}")
print(f"Hallucination Score: {score}")

