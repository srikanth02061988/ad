import openai

openai.api_type = "azure"
openai.api_version = "2024-02-01"
openai.api_base = "https://your-api-endpoint.azure.com/"
openai.api_key = "your-api-key"

input_text = "Who were the founders of Microsoft?"
output_text = "Microsoft was founded by Bill Gates and Paul Allen."

system_prompt = """
You are an AI assistant tasked with detecting open-domain hallucinations in the following response.
An open-domain hallucination is an inaccurate or unmotivated claim about the world.
Please answer with "Yes" or "No" and provide a brief explanation.

Input: {input_text}
Response: {output_text}
Does the response contain open-domain hallucinations? Explain your reasoning.
"""

def call_llm_model(prompt):
    response = openai.ChatCompletion.create(
        engine="",
        messages=[
            {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message['content'].strip()

def detect_hallucinations(input_text, output_text, num_runs=5):
    hallucination_count = 0
    prompt = system_prompt.format(input_text=input_text, output_text=output_text)

    for _ in range(num_runs):
        response = call_llm_model(prompt)
        print(f"Response {_ + 1}: {response}")
        if "yes" in response.lower():
            hallucination_count += 1

    hallucination_score = hallucination_count / num_runs
    is_hallucination = hallucination_score > 0.5

    return is_hallucination, hallucination_score

is_hallucination, score = detect_hallucinations(input_text, output_text)

print(f"\nFinal Result:")
print(f"Input: {input_text}")
print(f"Output: {output_text}")
print(f"Is Hallucination: {is_hallucination}")
print(f"Hallucination Score: {score}")

