import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
import psycopg2
from psycopg2.extras import execute_values
import numpy as np
import os
import logging
import requests
import json
import uuid
from openai import AzureOpenAI
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
import io
import base64

client = AzureOpenAI(
    api_version="2024-02-01",
    azure_endpoint="https://effopenai.openai.azure.com/",
    api_key="7896c56d537df41980034ac85b9d9bc9"
)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

azure_endpoint = "https://effopenai.openai.azure.com"
azure_api_key = "7896c56d537df41980034ac85b9d9bc9"
embedding_deployment = "TEB-Robin"
completion_deployment = "ajitTest"

headers = {
    "Content-Type": "application/json",
    "api-key": azure_api_key
}

def get_embeddings(text, endpoint, headers, deployment=embedding_deployment):
    try:
        logger.info(f"Generating embeddings for the text chunk: {text[:30]}...")
        url = f"{endpoint.strip()}/openai/deployments/{deployment}/embeddings?api-version=2024-02-15-preview"
        logger.info(f"Request URL: {url}")
        logger.info(f"Request Headers: {headers}")
        data = {"input": text}
        logger.info(f"Request Data: {data}")
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        embedding = result['data'][0]['embedding']
        logger.info("Embeddings generated successfully.")
        print("Generated Embeddings:", embedding)
        return embedding
    except requests.exceptions.RequestException as e:
        logger.error(f"Error generating embeddings: {e}")
        st.error(f"An error occurred while generating embeddings: {e}")
        return None

def get_pdf_text(pdf_docs):
    text = ""
    try:
        logger.info("Extracting text from PDF...")
        reader = PdfReader(pdf_docs)
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                cleaned_text = page_text.replace('\x00', '')
                text += cleaned_text
        logger.info("Text extraction from PDF successful.")
    except Exception as e:
        logger.error(f"Error extracting text from PDF: {e}")
        st.error(f"An error occurred while extracting text from PDF: {e}")
    return text

def get_text_chunks(text):
    logger.info("Splitting text into chunks...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)
    chunks = text_splitter.split_text(text)
    logger.info(f"Text split into {len(chunks)} chunks.")
    return chunks

def store_embeddings_in_db(pdf_id, text_chunks, endpoint, headers):
    try:
        logger.info("Connecting to PostgreSQL database...")
        conn = psycopg2.connect(
            host="npceffepsql.postgres.database.azure.com",
            port="5432",
            database="Digital_marketing_Embeddings",
            user="pgadmin",
            password="npceeff8kS"
        )

        with conn.cursor() as cur:
            logger.info("Creating table if it does not exist...")
            cur.execute("""
            CREATE TABLE IF NOT EXISTS embeddings (
                id BIGSERIAL PRIMARY KEY,
                pdf_id UUID,
                content TEXT,
                embedding VECTOR(1536)
            )
            """)
            conn.commit()

        embeddings = []
        for chunk in text_chunks:
            logger.info(f"Generating embedding for chunk: {chunk[:30]}...")
            embedding = get_embeddings(chunk, endpoint, headers)
            if embedding is not None:
                embedding_vector = list(map(float, embedding))
                embeddings.append((pdf_id, chunk, embedding_vector))
            else:
                logger.error("Failed to generate embedding for a chunk, skipping it.")
        
        if embeddings:
            with conn.cursor() as cur:
                logger.info("Inserting embeddings into the database...")
                execute_values(cur, "INSERT INTO embeddings (pdf_id, content, embedding) VALUES %s", embeddings)
                conn.commit()
        else:
            logger.error("No embeddings generated to store in the database.")

        conn.close()
    except Exception as e:
        logger.error(f"Error storing embeddings in database: {e}")
        st.error(f"An error occurred while storing embeddings in the database: {e}")

def retrieve_embeddings_from_db(pdf_id):
    try:
        logger.info("Connecting to PostgreSQL database for retrieval...")
        conn = psycopg2.connect(
            host="npceffepsql.postgres.database.azure.com",
            port="5432",
            database="Digital_marketing_Embeddings",
            user="pgadmin",
            password="npceeff8kS"
        )

        with conn.cursor() as cur:
            logger.info(f"Retrieving embeddings for PDF ID: {pdf_id}...")
            cur.execute("SELECT content, embedding::text FROM embeddings WHERE pdf_id = %s", (pdf_id,))
            rows = cur.fetchall()
        conn.close()

        if rows:
            docs = [row[0] for row in rows]
            embeddings = np.array([list(map(float, row[1][1:-1].split(','))) for row in rows], dtype=np.float32)
            print("Retrieved Embeddings:", embeddings)
            return docs, embeddings
        else:
            logger.info("No embeddings found for the given PDF ID.")
            return None, None
    except Exception as e:
        logger.error(f"Error retrieving embeddings from database: {e}")
        st.error(f"An error occurred while retrieving embeddings from the database: {e}")
        return None, None

def find_relevant_chunks(question, docs, embeddings, top_k=5):
    # Implementation for finding relevant chunks
    return docs[:top_k]

def generate_responses(prompt, relevant_docs, client, deployment="ajitTest"):
    try:
        logger.info("Generating responses for the question...")
        combined_docs = "\n\n".join(relevant_docs)
        full_prompt = f"{prompt}\n\nDocuments:\n\n{combined_docs}"
        response = client.chat_completions.create(
            model=deployment,
            messages=[
                {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
                {"role": "user", "content": full_prompt}
            ]
        )
        text_responses = [choice.message['content'].strip() for choice in response.choices]
        logger.info(f"Response from OpenAI: {text_responses}")
        return text_responses
    except Exception as e:
        logger.error(f"Error generating responses: {e}")
        st.error(f"An error occurred while generating responses: {e}")
        return None

def create_pdf(content):
    buffer = io.BytesIO()
    pdf = canvas.Canvas(buffer, pagesize=letter)
    pdf.setFont("Helvetica", 12)
    pdf.drawString(30, 750, content)
    pdf.save()
    buffer.seek(0)
    return buffer

def main():
    st.set_page_config(page_title="Derived content uc generator app")
    st.header("Derived content uc generator app")
    tab1, tab2 = st.tabs(["Upload & Generate", "Developer Prompt"])

    with tab1:
        pdf_docs = st.file_uploader("Upload your PDF Files", type=["pdf"])
        if pdf_docs and st.button("Submit PDF"):
            with st.spinner("Processing..."):
                raw_text = get_pdf_text(pdf_docs)
                if raw_text:
                    text_chunks = get_text_chunks(raw_text)
                    pdf_id = str(uuid.uuid4())
                    store_embeddings_in_db(pdf_id, text_chunks, azure_endpoint, headers)
                    st.session_state["pdf_id"] = pdf_id
                    st.session_state["text_chunks"] = text_chunks
                    st.sidebar.success("PDF processed and embeddings stored.")
                else:
                    logger.error("No text extracted from PDF.")
                    st.error("Failed to extract text from the uploaded PDF.")

    with tab2:
        if "pdf_id" in st.session_state:
            category = st.selectbox("Select the category to search within:", ["Twitter", "LinkedIn", "Other"])
            if st.button("Next"):
                st.session_state["category"] = category
                st.experimental_rerun()
            if "category" in st.session_state:
                with open("prompts.json") as file:
                    prompts = json.load(file)
                system_prompt = prompts.get(category, "Default prompt")
                text_chunks = st.session_state.get("text_chunks", [])
                responses = generate_responses(system_prompt, text_chunks, client)
                if responses:
                    st.write("Responses:")
                    for response in responses:
                        st.markdown(f'<div class="response-container"><div class="response">{response}</div><div class="thumbs-up" onclick="selectResponse(\'{response}\')">üëç</div></div>', unsafe_allow_html=True)
                    st.markdown(
                        """
                        <script>
                        function selectResponse(response) {
                            fetch('/select-response', {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                },
                                body: JSON.stringify({response: response}),
                            }).then(response => response.json()).then(data => {
                                console.log('Response selected:', data);
                                window.location.href = '/download-response';
                            });
                        }
                        </script>
                        """,
                        unsafe_allow_html=True
                    )
                else:
                    st.error("Failed to generate responses.")

    st.experimental_rerun()

if __name__ == "__main__":
    main()
