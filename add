import streamlit as st
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
import psycopg2
from psycopg2.extras import execute_values
import numpy as np
import logging
import json
import requests
from fpdf import FPDF
from uuid import uuid4

# Configuration for Azure OpenAI
from azure.identity import DefaultAzureCredential
from azure.ai.openai import OpenAIClient

client = OpenAIClient(
    endpoint="https://effopenai.openai.azure.com/",
    credential=DefaultAzureCredential()
)

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Hardcoded header image URL and footer image path
HEADER_IMAGE_URL = "https://example.com/path/to/header/image.jpg"
FOOTER_IMAGE_PATH = "/path/to/footer/image.png"

# Function to get embeddings
def get_embeddings(text, endpoint, headers, deployment):
    try:
        logging.info(f"Generating embeddings for the text chunk: {text[:30]}...")
        url = f"{endpoint.strip()}/openai/deployments/{deployment}/embeddings?api-version=2024-02-15-preview"
        data = {"input": text}
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        embedding = result['data'][0]['embedding']
        logging.info("Embeddings generated successfully.")
        return embedding
    except requests.exceptions.RequestException as e:
        logging.error(f"Error generating embeddings: {e}")
        st.error(f"An error occurred while generating embeddings: {e}")
        return None

# Function to extract text from PDF
def get_pdf_text(pdf_docs):
    text = ""
    try:
        logging.info("Extracting text from PDF...")
        with pdfplumber.open(pdf_docs) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    cleaned_text = page_text.replace('\n', ' ')
                    text += cleaned_text
        logging.info("Text extraction from PDF successful.")
    except Exception as e:
        logging.error(f"Error extracting text from PDF: {e}")
        st.error(f"An error occurred while extracting text from PDF: {e}")
    return text

# Function to split text into chunks
def get_text_chunks(text):
    logging.info("Splitting text into chunks...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)
    chunks = text_splitter.split_text(text)
    logging.info(f"Text split into {len(chunks)} chunks.")
    return chunks

# Function to store embeddings in database
def store_embeddings_in_db(pdf_id, text_chunks, endpoint, headers):
    try:
        logging.info("Connecting to PostgreSQL database...")
        conn = psycopg2.connect(
            host="ncepffspql.postgres.database.azure.com",
            port="5432",
            database="digital_marketing_embeddings",
            user="pgadmin",
            password="ncepffK8s"
        )
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS embeddings (
                    id SERIAL PRIMARY KEY,
                    pdf_id UUID,
                    content TEXT,
                    embedding VECTOR(1536)
                )
            """)
            conn.commit()

            embeddings = []
            for chunk in text_chunks:
                logging.info(f"Generating embedding for chunk: {chunk[:30]}...")
                embedding = get_embeddings(chunk, endpoint, headers, deployment="embedding_deployment")
                if embedding is not None:
                    embeddings.append((pdf_id, chunk, embedding))
                else:
                    logging.error("Failed to generate embedding for a chunk, skipping it.")

            if embeddings:
                logging.info("Inserting embeddings into the database...")
                execute_values(cur, """
                    INSERT INTO embeddings (pdf_id, content, embedding) VALUES %s
                """, embeddings)
                conn.commit()
            else:
                logging.error("No embeddings generated to store in the database.")
        conn.close()
    except Exception as e:
        logging.error(f"Error storing embeddings in database: {e}")
        st.error(f"An error occurred while storing embeddings in the database: {e}")

# Function to retrieve embeddings from database
def retrieve_embeddings_from_db(pdf_id):
    try:
        logging.info("Connecting to PostgreSQL database for retrieval...")
        conn = psycopg2.connect(
            host="ncepffspql.postgres.database.azure.com",
            port="5432",
            database="digital_marketing_embeddings",
            user="pgadmin",
            password="ncepffK8s"
        )
        with conn.cursor() as cur:
            logging.info(f"Retrieving embeddings for PDF ID: {pdf_id}...")
            cur.execute("SELECT content, embedding::TEXT FROM embeddings WHERE pdf_id = %s", (pdf_id,))
            rows = cur.fetchall()
            conn.close()

            if rows:
                docs = [row[0] for row in rows]
                embeddings = np.array([list(map(float, row[1][1:-1].split(','))) for row in rows], dtype=np.float32)
                return docs, embeddings
            else:
                logging.error("No embeddings found for the given PDF ID.")
                return None, None
    except Exception as e:
        logging.error(f"Error retrieving embeddings from database: {e}")
        st.error(f"An error occurred while retrieving embeddings from the database: {e}")
        return None, None

# Function to find relevant chunks
def find_relevant_chunks(question, docs, embeddings, top_k=5):
    return docs[:top_k]

# Function to generate responses
def generate_responses(question, relevant_docs, client, deployment):
    try:
        logging.info("Generating responses for the question...")
        combined_docs = "\n\n".join(relevant_docs)
        responses = []
        for i in range(2):  # Generate two responses
            response = client.chat.completions.create(
                model=deployment,
                messages=[
                    {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
                    {"role": "user", "content": question}
                ]
            )
            text_response = response.choices[0].message.content.strip()
            responses.append(text_response)
            logging.info(f"Response {i+1} from OpenAI: {text_response}")
        return responses
    except Exception as e:
        logging.error(f"Error generating responses: {e}")
        st.error(f"An error occurred while generating responses: {e}")
        return None

# Function to create a PDF with header and footer images
def create_pdf(content, file_name="response.pdf"):
    pdf = FPDF()
    pdf.add_page()

    # Add header image
    if HEADER_IMAGE_URL:
        pdf.image(HEADER_IMAGE_URL, x=10, y=8, w=190)

    pdf.set_font("Arial", size=12)
    pdf.ln(20)  # Add space below header image
    pdf.multi_cell(0, 10, content)

    # Add footer image
    pdf.ln(10)
    pdf.image(FOOTER_IMAGE_PATH, x=10, y=pdf.get_y(), w=190)

    pdf.output(file_name)
    return file_name

# Function to display responses and handle selection
def display_responses(text_responses):
    if text_responses:
        if len(text_responses) > 1:
            col1, col2 = st.columns(2)
            with col1:
                st.write("Response 1:")
                st.write(text_responses[0])
                if st.button("Select Response 1"):
                    st.session_state["selected_response"] = text_responses[0]
            with col2:
                st.write("Response 2:")
                st.write(text_responses[1])
                if st.button("Select Response 2"):
                    st.session_state["selected_response"] = text_responses[1]
        else:
            st.write("Response:")
            st.write(text_responses[0])
            st.session_state["selected_response"] = text_responses[0]

        st.write("Selected Response:")
        st.write(st.session_state.get("selected_response", ""))
        if st.session_state.get("selected_response"):
            pdf_file = create_pdf(st.session_state["selected_response"])
            st.download_button("Download Response as PDF", data=open(pdf_file, "rb").read(), file_name="response.pdf")
    else:
        st.error("Failed to generate responses.")

# Main function to run the Streamlit app
def main():
    st.set_page_config(page_title="Derived Content UC Generator App")
    st.header("Derived Content UC Generator App")
    st.sidebar.title("Menu")
    tab1, tab2 = st.tabs(["Upload & Generate", "Developer Prompt"])

    with tab1:
        pdf_docs = st.sidebar.file_uploader("Upload your PDF files", type=["pdf"])
        if pdf_docs is not None and st.sidebar.button("Submit PDF"):
            with st.spinner("Processing..."):
                raw_text = get_pdf_text(pdf_docs)
                pdf_id = str(uuid4())
                text_chunks = get_text_chunks(raw_text)
                store_embeddings_in_db(pdf_id, text_chunks, client.endpoint, headers)
                st.session_state["pdf_id"] = pdf_id
                st.session_state["text_chunks"] = text_chunks
                st.session_state["category"] = None
                st.success("PDF processed and embeddings stored.")
                if "pdf_id" in st.session_state:
                    user_question = st.text_input("Ask a question based on the uploaded PDF", height=200)
                    if st.button("Generate Responses"):
                        docs, embeddings = retrieve_embeddings_from_db(st.session_state["pdf_id"])
                        if docs and embeddings is not None:
                            relevant_docs = find_relevant_chunks(user_question, docs, embeddings)
                            text_responses = generate_responses(user_question, relevant_docs, client, "ajitTest")
                            display_responses(text_responses)
                        else:
                            st.error("No relevant embeddings found for the uploaded PDF.")

    with tab2:
        if "pdf_id" in st.session_state:
            user_question = st.text_input("Ask a question based on the uploaded PDF", height=200)
            if st.button("Submit"):
                docs, embeddings = retrieve_embeddings_from_db(st.session_state["pdf_id"])
                if docs and embeddings is not None:
                    relevant_docs = find_relevant_chunks(user_question, docs, embeddings)
                    text_responses = generate_responses(user_question, relevant_docs, client, "ajitTest")
                    display_responses(text_responses)
                else:
                    st.error("No relevant embeddings found for the uploaded PDF.")
        else:
            st.warning("Please upload and process a PDF in the 'Upload & Generate' tab first.")

if __name__ == "__main__":
    main()

